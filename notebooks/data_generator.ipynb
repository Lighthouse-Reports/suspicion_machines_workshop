{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad58771c",
   "metadata": {},
   "source": [
    "Author: Justin Braun\n",
    "\n",
    "Date: 20221119\n",
    "\n",
    "Purpose: Generate input data for experiment based on ini config files. Loops over all ini files in '../conf' and outputs single csv file with combinations and sliced data. Combinations data is a copy of the training/synthetic data for each possible combination of values in the variable_list, which are not in violation of the business rule.  'data_generator()' in the final cell calls all other functions.\n",
    "\n",
    "Also note that some combinations between variables we are interested in may violate business rules. These combinations can be removed from the data by specifying them in 'excluded_combinations' in the ini file.\n",
    "\n",
    "Final point, in Data Generator, look for \"CHECK\" comments and specify file paths and whether you have access to the real training data which is not publicly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f42b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import ast\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62450350",
   "metadata": {},
   "source": [
    "## Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "675f8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config files\n",
    "#\n",
    "# @param config_path: file path to an ini file, which contains configuration data for a single experiment\n",
    "#\n",
    "# @return conf: A dictionary which matches the config file in config path. File paths are concatenated within the function\n",
    "def read_config(conf_path): \n",
    "    #read config file\n",
    "    config = configparser.ConfigParser(allow_no_value=True)\n",
    "    config.read(conf_path)\n",
    "    \n",
    "    conf = {} #set up conf dictionary\n",
    "    \n",
    "    #load meta data\n",
    "    meta = config['META']\n",
    "    conf['user'] = meta['user']\n",
    "    conf['date'] = meta['date']\n",
    "    conf['name'] = meta['name']\n",
    "    \n",
    "    #generate destination file path (where the output csv will be saved)\n",
    "    conf['dest_filename'] = '../data/03_experiment_input/'+conf['date']+'_'+conf['user']+'_'+conf['name']+'.csv'\n",
    "    print('Destination Filename: ' + conf['dest_filename'])\n",
    "    \n",
    "    #generate input filepaths for real and synthetic data\n",
    "    filepaths = config['FILEPATHS']\n",
    "    conf['real_fp'] = filepaths['real']\n",
    "    conf['synth_fp'] = filepaths['synth']\n",
    "    print('Real Source FP: '+ conf['real_fp'])\n",
    "    print('Synth Source FP: '+ conf['synth_fp'])\n",
    "    \n",
    "    #store variable list as list of lists of dictionaries\n",
    "    variables = config['VARIABLES']\n",
    "    variable_list = variables['variable_list']\n",
    "    variable_list = variable_list.replace('“', '\"')\n",
    "    variable_list = variable_list.replace('”', '\"')\n",
    "    conf['variable_list'] = ast.literal_eval(variable_list) #evaluate string to list of lists of dictionaries\n",
    "    print('Variable list:')\n",
    "    print(conf['variable_list'])\n",
    "    \n",
    "    excluded_combinations = variables['excluded_combinations']\n",
    "    conf['excluded_combinations'] = ast.literal_eval(excluded_combinations)\n",
    "    print('Excluded combinations:')\n",
    "    print(conf['excluded_combinations'])\n",
    "    return conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efb07c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827ae6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#\n",
    "# @param filepath: file path to the training data\n",
    "#\n",
    "# @return df: pandas dataframe of the training data\n",
    "def load_data(fp):\n",
    "    #CHECK: if you are running this code on a Windows machine, you may have to include the argument \"encoding = 'latin'\"\n",
    "    df = pd.read_csv(fp) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eca36d",
   "metadata": {},
   "source": [
    "## Check User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b28e4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check User Inputs\n",
    "#\n",
    "# @param td: pandas dataframe for the training data\n",
    "# @variable_list: list of lists of dictionary containing all the variables\n",
    "#\n",
    "# Purpose: checks that user inputs actually correspond to variables in td and change variable_list values for variables\n",
    "# where 'ALL' is specified to all unique values of that variable\n",
    "def check_user_inputs(td, variable_list):\n",
    "    col_names = list(td.columns.values) #all column names\n",
    "    for nested_list in variable_list:\n",
    "        for dic in nested_list:\n",
    "            #print(dic)\n",
    "            var = list(dic.keys())[0] #var name in variable_list\n",
    "            assert_message = var + ' is not a column name.' #warning message if variable name is not contained in td\n",
    "            \n",
    "            #assert that user inputs actually correspond to variables in td\n",
    "            assert var in col_names, assert_message \n",
    "            \n",
    "            #if variable values are specified as 'ALL', change to all unique values for this variable\n",
    "            if (dic[var] == ['ALL']):\n",
    "                dic[var] = list(td[var].unique())\n",
    "            dic[var] = list(map(pd.to_numeric, dic[var]))\n",
    "    print('All chosen variables correspondond to columns in the dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4fda38",
   "metadata": {},
   "source": [
    "## Slice Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d18699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice Data\n",
    "#\n",
    "# @param df: pandas dataframe to be sliced\n",
    "# @param variable_list: list of lists of dictionaries containing variable values, df rows have to meet to remain\n",
    "# @param data_type: string specifying which data type this particular df is, e.g., 'real' or 'synth'\n",
    "#\n",
    "# @return df_copy: pandas dataframe sliced according to the values specified in variable_list\n",
    "def slice_data(df, variable_list, dt):\n",
    "    df_copy = copy.deepcopy(df) #make a copy of the original df\n",
    "    \n",
    "    for nested_list in variable_list:\n",
    "        for dic in nested_list:\n",
    "            var = list(dic.keys())[0]\n",
    "            df_copy = df_copy.loc[df_copy[var].isin(dic[var])] #subset df_copy by values for each variable\n",
    "    \n",
    "    df_copy['data_type'] = dt #set data_type column\n",
    "    print(dt + ' copied, shape: ' + str(df_copy.shape))\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a1bc4",
   "metadata": {},
   "source": [
    "## Business Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0122d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Zero One Hot Encoded Is Valid\n",
    "#\n",
    "# @param column_names: list of column names\n",
    "# @param data: pandas data frame\n",
    "#\n",
    "# @return bool_list: returns boolean list, where True elements correspond to rows\n",
    "# in accordance with the business rule and False elements correspond to rows which violate the business rule.\n",
    "#\n",
    "# Purpose: Is valid when either 1 or 0 of the columns in column_names are coded as one\n",
    "def zero_one_hot_encoding_is_valid(column_names, data):\n",
    "    temp=data.loc[:, column_names]\n",
    "    is_zero_or_one_hot_encoded = (temp.sum(axis=1) <= 1)\n",
    "    return is_zero_or_one_hot_encoded\n",
    "\n",
    "#test\n",
    "data = [[0,0],[0,1],[1,0],[1,1],[1,2],[2,1],[2,2]]\n",
    "test_df = pd.DataFrame(data, columns=['refcol', 'col1'])\n",
    "test_fn = zero_one_hot_encoding_is_valid(['col1', 'refcol'], test_df)\n",
    "print(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9676a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "6     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Zero or GE Is Valid\n",
    "#\n",
    "# @param column_names: list of column names\n",
    "# @param data: pandas data frame\n",
    "# @param ref_column: name of a column in data\n",
    "#\n",
    "# @return bool_list: returns boolean list, where True elements correspond to rows\n",
    "# in accordance with the business rule and False elements correspond to rows which violate the business rule.\n",
    "#\n",
    "# Purpose: Is valid when all columns are zero or when ref column is smaller than all columns in column_names. For\n",
    "# instance, when 'relatie_kind_heeft_kinderen' = 0, 'relatie_kind_huidige_aantal' also has to be 0. Conversely,\n",
    "# when 'relatie_kind_heeft_kinderen' = 1, then 'relatie_kind_huidige_aantal' >= 1.\n",
    "def zero_or_ge_is_valid(column_names, data, ref_column):\n",
    "    ret_list = [True for i in range(len(data.index))]\n",
    "    for col in column_names:\n",
    "        temp_list = (data[ref_column] >= data[col])\n",
    "        ret_list = temp_list & ret_list\n",
    "    return ret_list\n",
    "\n",
    "#test\n",
    "data = [[0,0],[0,1],[1,0],[1,1],[1,2],[2,1],[2,2]]\n",
    "test_df = pd.DataFrame(data, columns=['refcol', 'col1'])\n",
    "test_fn = zero_or_ge_is_valid(['col1'], test_df, 'refcol')\n",
    "print(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b99d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "6     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Zero Must Match\n",
    "#\n",
    "# @param column_names: list of column names\n",
    "# @param data: pandas data frame\n",
    "# @param ref_column: name of a column in data\n",
    "#\n",
    "# @return bool_list: returns boolean list, where True elements correspond to rows\n",
    "# in accordance with the business rule and False elements correspond to rows which violate the business rule.\n",
    "#\n",
    "# Purpose: Is valid if when ref_column is zero and all columns in column_names are also zero.\n",
    "# If ref_column is not zero, other columns can vary. For instance, if an individual has 'ontheffing_hist_ind' = 0,\n",
    "# all other 'ontheffing_hist*' also have to be zero. If 'ontheffing_hist_ind' = 1, the other 'ontheffing_hist*' can vary.\n",
    "def zero_must_match_is_valid(column_names, data, ref_column):\n",
    "    ret_list = [True for i in range(len(data.index))]\n",
    "    for col in column_names:\n",
    "        temp_list = (((data[ref_column] == 0) & (data[col] == 0)) | (data[ref_column] > 0))\n",
    "        ret_list = temp_list & ret_list\n",
    "    return ret_list\n",
    "\n",
    "#test function\n",
    "data = [[0,0],[0,1],[1,0],[1,1],[1,2],[2,1],[2,2]]\n",
    "test_df = pd.DataFrame(data, columns=['refcol', 'col1'])\n",
    "test_fn = zero_must_match_is_valid(['col1'], test_df, 'refcol')\n",
    "print(test_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd746aa4",
   "metadata": {},
   "source": [
    "## Check Business Rules Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa44072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Business Rules Violations\n",
    "#\n",
    "# @param comb_list: list of pandas dataframes, to be checked for business rules violations\n",
    "#\n",
    "# @return comb_list: list of pandas dataframes, where rows have been removed from all dataframes, \n",
    "# which are in violation of any business rules for any of the dataframes in comb_list\n",
    "def check_bus_rules_violations(comb_list):\n",
    "    \n",
    "    #initialize bool_list, which is used to subset the dataframes in comb_list\n",
    "    df = comb_list[0]\n",
    "    bool_list = pd.Series(True, index=df.index) #initialize to all true\n",
    "    \n",
    "    #for each dataframe, check if any of the business rules is violated\n",
    "    for index in range(len(comb_list)):\n",
    "        df = comb_list[index] #extract dataframe\n",
    "        \n",
    "        district_vars = ['adres_recentste_wijk_charlois', 'adres_recentste_wijk_delfshaven', 'adres_recentste_wijk_feijenoord',\n",
    "                   'adres_recentste_wijk_ijsselmonde', 'adres_recentste_wijk_kralingen_c', 'adres_recentste_wijk_noord',\n",
    "                   'adres_recentste_wijk_other', 'adres_recentste_wijk_prins_alexa', 'adres_recentste_wijk_stadscentru']\n",
    "        bool_list = (zero_one_hot_encoding_is_valid(district_vars, df) & bool_list)\n",
    "        #print('1: ', bool_list.value_counts())\n",
    "                \n",
    "        neighborhood_vars = ['adres_recentste_buurt_groot_ijsselmonde', 'adres_recentste_buurt_nieuwe_westen', 'adres_recentste_buurt_other',\n",
    "                   'adres_recentste_buurt_oude_noorden', 'adres_recentste_buurt_vreewijk']\n",
    "        bool_list = (zero_one_hot_encoding_is_valid(neighborhood_vars, df) & bool_list)\n",
    "        #print('2: ', bool_list.value_counts())\n",
    "            \n",
    "        bool_list = (zero_one_hot_encoding_is_valid(['adres_recentste_plaats_other','adres_recentste_plaats_rotterdam'], df) & bool_list)\n",
    "        #print('3: ', bool_list.value_counts())        \n",
    "        \n",
    "        district_neighborhood_plaats = district_vars + neighborhood_vars + ['adres_recentste_plaats_rotterdam']\n",
    "        district_neighborhood_plaats = list(set(district_neighborhood_plaats) - set(['adres_recentste_wijk_delfshaven', 'adres_recentste_wijk_other', 'adres_recentste_buurt_other']))\n",
    "        bool_list = (zero_or_ge_is_valid(district_neighborhood_plaats, df, 'adres_recentst_onderdeel_rdam') & bool_list)\n",
    "        #print('4: ', bool_list.value_counts())      \n",
    "        \n",
    "        district_neighborhood_plaats.remove('adres_recentste_plaats_rotterdam')\n",
    "        district_neighborhood = district_neighborhood_plaats\n",
    "        bool_list = (zero_or_ge_is_valid(district_neighborhood, df, 'adres_recentste_plaats_rotterdam') & bool_list)\n",
    "        #print('5: ', bool_list.value_counts())        \n",
    "        \n",
    "        district_neighborhood_matches = {'adres_recentste_wijk_noord':'adres_recentste_buurt_oude_noorden',\n",
    "                                'adres_recentste_wijk_feijenoord':'adres_recentste_buurt_vreewijk',\n",
    "                                'adres_recentste_wijk_ijsselmonde':'adres_recentste_buurt_groot_ijsselmonde',\n",
    "                                'adres_recentste_wijk_delfshaven':'adres_recentste_buurt_nieuwe_westen'}\n",
    "        for key, value in district_neighborhood_matches.items():\n",
    "            bool_list = (zero_or_ge_is_valid([value], df, key) & bool_list)\n",
    "            #print('5: ', bool_list.value_counts())\n",
    "                        \n",
    "        bool_list = (zero_must_match_is_valid(['adres_recentste_wijk_other'], df, 'adres_recentste_buurt_other') & bool_list)\n",
    "        #print('6: ', bool_list.value_counts())        \n",
    "        \n",
    "        reading_vars = ['persoonlijke_eigenschappen_nl_lezen3', 'persoonlijke_eigenschappen_nl_lezen4']\n",
    "        bool_list = (zero_one_hot_encoding_is_valid(reading_vars, df) & bool_list)\n",
    "        #print('7: ', bool_list.value_counts())\n",
    "        \n",
    "        writing_vars = ['persoonlijke_eigenschappen_nl_schrijven0', 'persoonlijke_eigenschappen_nl_schrijven1', 'persoonlijke_eigenschappen_nl_schrijven2',\n",
    "                'persoonlijke_eigenschappen_nl_schrijven3', 'persoonlijke_eigenschappen_nl_schrijvenfalse']\n",
    "        bool_list = (zero_one_hot_encoding_is_valid(writing_vars, df) & bool_list)\n",
    "        #print('8: ', bool_list.value_counts())\n",
    "            \n",
    "        speaking_vars = ['persoonlijke_eigenschappen_nl_spreken1', 'persoonlijke_eigenschappen_nl_spreken2',\n",
    "           'persoonlijke_eigenschappen_nl_spreken3']\n",
    "        bool_list = (zero_one_hot_encoding_is_valid(speaking_vars, df) & bool_list)\n",
    "        #print('9: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['afspraak_laatstejaar_aantal_woorden'], df, 'afspraak_aantal_woorden') & bool_list)\n",
    "        #print('10: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['afspraak_laatstejaar_resultaat_ingevuld_uniek'], df, 'afspraak_resultaat_ingevuld_uniek') & bool_list)\n",
    "        #print('11: ', bool_list.value_counts())\n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden'], df, 'beschikbaarheid_huidig_bekend') & bool_list)\n",
    "        #print('12: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['beschikbaarheid_recent_afwijkend_wegens_medische_omstandigheden', 'beschikbaarheid_huidig_afwijkend_wegens_medische_omstandigheden'], df, 'beschikbaarheid_aantal_historie_afwijkend_wegens_medische_omstandigheden') & bool_list)\n",
    "        #print('13: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['beschikbaarheid_recent_afwijkend_wegens_sociaal_maatschappelijke_situatie'], df, 'beschikbaarheid_aantal_historie_afwijkend_wegens_sociaal_maatschappelijke_situatie') & bool_list)\n",
    "        #print('14: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_one_hot_encoding_is_valid(['beschikbaarheid_recent_afwijkend_wegens_medische_omstandigheden', \n",
    "                                                             'beschikbaarheid_recent_afwijkend_wegens_sociaal_maatschappelijke_situatie'], df) & bool_list)\n",
    "        #print('15: ', bool_list.value_counts())        \n",
    "        \n",
    "        contacten_matches = {'contacten_onderwerp__arbeids_motivatie':'contacten_onderwerp_boolean__arbeids_motivatie',\n",
    "                 'contacten_onderwerp__pre__intake':'contacten_onderwerp_boolean__pre__intake',\n",
    "                 'contacten_onderwerp__werk_intake':'contacten_onderwerp_boolean__werk_intake',\n",
    "                 'contacten_onderwerp_beoordelen_taaleis':'contacten_onderwerp_boolean_beoordelen_taaleis',\n",
    "                 'contacten_onderwerp_contact_derden':'contacten_onderwerp_boolean_contact_derden',\n",
    "                 'contacten_onderwerp_contact_met_aanbieder':'contacten_onderwerp_boolean_contact_met_aanbieder',\n",
    "                 'contacten_onderwerp_diagnosegesprek':'contacten_onderwerp_boolean_diagnosegesprek',\n",
    "                 'contacten_onderwerp_documenten__innemen_':'contacten_onderwerp_boolean_documenten__innemen_',\n",
    "                 'contacten_onderwerp_documenttype__cv_':'contacten_onderwerp_boolean_documenttype__cv_',\n",
    "                 'contacten_onderwerp_documenttype__overeenkomst_':'contacten_onderwerp_boolean_documenttype__overeenkomst_',\n",
    "                 'contacten_onderwerp_financiële_situatie':'contacten_onderwerp_boolean_financiële_situatie',\n",
    "                 'contacten_onderwerp_groepsbijeenkomst':'contacten_onderwerp_boolean_groepsbijeenkomst',\n",
    "                 'contacten_onderwerp_inkomen':'contacten_onderwerp_boolean_inkomen',\n",
    "                 'contacten_onderwerp_maatregel_overweging':'contacten_onderwerp_boolean_maatregel_overweging',\n",
    "                 'contacten_onderwerp_matching':'contacten_onderwerp_boolean_matching',\n",
    "                 'contacten_onderwerp_mutatie':'contacten_onderwerp_boolean_mutatie',\n",
    "                 'contacten_onderwerp_no_show':'contacten_onderwerp_boolean_no_show',\n",
    "                 'contacten_onderwerp_overige':'contacten_onderwerp_boolean_overige',\n",
    "                 'contacten_onderwerp_overleg_met_inkomen':'contacten_onderwerp_boolean_overleg_met_inkomen',\n",
    "                 'contacten_onderwerp_scholing':'contacten_onderwerp_boolean_scholing',\n",
    "                 'contacten_onderwerp_terugbelverzoek':'contacten_onderwerp_boolean_terugbelverzoek',\n",
    "                 'contacten_onderwerp_traject':'contacten_onderwerp_boolean_traject',\n",
    "                 'contacten_onderwerp_uitnodiging':'contacten_onderwerp_boolean_uitnodiging',\n",
    "                 'contacten_onderwerp_ziek__of_afmelding':'contacten_onderwerp_boolean_ziek__of_afmelding',\n",
    "                 'contacten_onderwerp_zorg':'contacten_onderwerp_boolean_zorg'}\n",
    "        for key, value in contacten_matches.items():\n",
    "            bool_list = (zero_or_ge_is_valid([value], df, key) & bool_list)\n",
    "            #print('16: ', bool_list.value_counts())           \n",
    "               \n",
    "        bool_list = (zero_or_ge_is_valid(['relatie_kind_heeft_kinderen'], df, 'relatie_kind_huidige_aantal') & bool_list)\n",
    "        #print('17: ', bool_list.value_counts())\n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['relatie_partner_huidige_partner___partner__gehuwd_'], df, 'relatie_partner_aantal_partner___partner__gehuwd_') & bool_list)\n",
    "        #print('18: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['pla_ondertekeningen_actueel'], df, 'pla_ondertekeningen_historie') & bool_list)\n",
    "        #print('19: ', bool_list.value_counts())        \n",
    "        \n",
    "        ontheffing_vars = ['ontheffing_reden_hist_medische_gronden','ontheffing_reden_hist_other', \n",
    "                   'ontheffing_reden_hist_sociale_gronden',\n",
    "                   'ontheffing_reden_hist_tijdelijke_ontheffing_arbeidsverpl__en_tegenprestatie',\n",
    "                   'ontheffing_reden_hist_tijdelijke_ontheffing_arbeidsverplichtingen',\n",
    "                   'ontheffing_reden_hist_vanwege_uw_sociaal_maatschappelijke_situatie',\n",
    "                   'ontheffing_dagen_hist_vanwege_uw_medische_omstandigheden', \n",
    "                   'ontheffing_dagen_hist_mean']\n",
    "        bool_list = (zero_must_match_is_valid(ontheffing_vars, df, 'ontheffing_hist_ind') & bool_list)\n",
    "        #print('20: ', bool_list.value_counts())        \n",
    "        \n",
    "        typering_vars = ['typering_indicatie_geheime_gegevens', 'typering_other',\n",
    "                 'typering_transport__logistiek___tuinbouw', 'typering_zorg__schoonmaak___welzijn',\n",
    "                 'typering_aantal', 'typering_ind', 'typering_hist_inburgeringsbehoeftig', \n",
    "                 'typering_hist_sector_zorg', 'typering_dagen_som']\n",
    "        bool_list = (zero_must_match_is_valid(typering_vars, df, 'typering_hist_ind') & bool_list)\n",
    "        #print('21: ', bool_list.value_counts())        \n",
    "        \n",
    "        bool_list = (zero_or_ge_is_valid(['typering_hist_ind'], df, 'typering_hist_aantal') & bool_list)\n",
    "        #print('22: ', bool_list.value_counts())\n",
    "    #print number of rows which are in violation of business rules\n",
    "    print('Number of rows matching business rules:\\n', str(bool_list.value_counts()))\n",
    "    \n",
    "    #exclude rows which are in violation of any business rule from all datafranes in comb_list\n",
    "    for index in range(len(comb_list)):\n",
    "        df = comb_list[index]\n",
    "        df = df[bool_list.values]\n",
    "        comb_list[index] = df\n",
    "        \n",
    "    return comb_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef239be",
   "metadata": {},
   "source": [
    "## Generate Combinations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb935405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check excluded combinations\n",
    "#\n",
    "# @param comb_list: list of pandas data frames\n",
    "# @param excluded_combinations: list of dictionaries specifying which combinations are not allowed\n",
    "#\n",
    "# @return temp_list: list of pandas data frames from which data frames that match one of the exclusion combinations have been removed\n",
    "#\n",
    "# Purpose: Certain variable value combinations for the list of combinations data frames can violate business rules.\n",
    "# For instance, if we want to look at the number of children, the copy where number of children = 0 will violate business rules\n",
    "# for observations where has children = 1. Conversely, setting number of children = 1 or greater will violate business\n",
    "# rules for cases where has children = 0. Thus all observations will be in violation of business rules for some copy C_i.\n",
    "# To account for this, this function removes copies C_i from the list of copies, when they match an exclusion restriction.\n",
    "# These restrictions should be specified by the user to make sure that instances are taken care off where every row will violate \n",
    "# some business rule.\n",
    "# Note that this function only runs on 'comb_list', i.e., a list of dataframes where for the variables in var_list\n",
    "# all rows have the same value. This means that we don't need to check whether every single row matches an \n",
    "# exclusion combination, but it suffices to check the first row.\n",
    "def check_excluded_combinations(comb_list, excluded_combinations):\n",
    "    print('Length comb_list before exclusion: ' + str(len(comb_list)))\n",
    "    temp_list = []\n",
    "    for df in comb_list: #iterate over dataframes\n",
    "        include = True\n",
    "        for dic in excluded_combinations: #iterate over dictionaries specifying exclusion restrictions\n",
    "            exclude = True\n",
    "            for key in dic:\n",
    "                if (df[key].values[0] != int(dic[key])): #case: an exclusion restriction is violated, i.e., the df doesn't need to be removed\n",
    "                    exclude = False\n",
    "                    break\n",
    "            if exclude:\n",
    "                include = False\n",
    "                break\n",
    "        if include: #case: no exclusion restriction has been violated, the df can stay\n",
    "            temp_list.append(df)\n",
    "    print('Length of comb_list after exclusion: ' + str(len(temp_list)))\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c7d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat combinations\n",
    "#\n",
    "# @param new_data: dataframe to be copied for each combination of variable values\n",
    "# @param variable_list: list of list of dictionaries specifying each variable and corresponding values\n",
    "# @param excluded_combinations: list of dictionaries specifying which combinations are not allowed\n",
    "#\n",
    "# @return new_data: concatenated copies of input new_data, one copy for every possible combination of variable values\n",
    "def concat_combinations(new_data, variable_list, excluded_combinations):\n",
    "    comb_list = [new_data] #put new_data into a list\n",
    "    \n",
    "    #each nested list corresponds to a single 'feature'. This can either be a single variable or multiple One Hot Encoded vars\n",
    "    #iterate over nested lists\n",
    "    for nested_list in variable_list:\n",
    "        #Hot One encoded case\n",
    "        if len(nested_list) > 1:\n",
    "            \n",
    "            #extract all variable names which are OHE\n",
    "            OHE_vars = []\n",
    "            for dic in nested_list:\n",
    "                OHE_vars.append(list(dic.keys())[0])\n",
    "            #set all OHE vars to zero\n",
    "            for df in comb_list:\n",
    "                df.loc[:, OHE_vars] = 0\n",
    "                \n",
    "            #for each OHE var create a copy of comb_list and set the var to 1\n",
    "            comb_list_temp = []\n",
    "            for cur_var in OHE_vars:\n",
    "                temp = copy.deepcopy(comb_list)\n",
    "                for df in temp:\n",
    "                    df[cur_var] = 1\n",
    "                comb_list_temp = comb_list_temp + temp\n",
    "            \n",
    "            #set comb_list equal to all the newly created copies\n",
    "            comb_list = comb_list_temp\n",
    "                \n",
    "        #Single variable case\n",
    "        else:\n",
    "            dic = nested_list[0]\n",
    "            var = list(dic.keys())[0] #extract var name\n",
    "            vals = dic[var] #get values for the variable\n",
    "            \n",
    "            #if a variable has more than 20 unique values, take a random sample of those values.\n",
    "            if len(vals) > 20:\n",
    "                random.seed(1)\n",
    "                vals = random.sample(vals, 20)\n",
    "                \n",
    "            #for each value, create a copy of comb_list and set var equal to value\n",
    "            comb_list_temp = []\n",
    "            for value in vals:\n",
    "                temp = copy.deepcopy(comb_list)\n",
    "                for df in temp:\n",
    "                    df[var] = value\n",
    "                comb_list_temp = comb_list_temp + temp\n",
    "                \n",
    "            #set comb_list equal to all the newly created copies\n",
    "            comb_list = comb_list_temp\n",
    "    \n",
    "    #exclude prohibited combinations of specified features\n",
    "    comb_list = check_excluded_combinations(comb_list, excluded_combinations)\n",
    "    \n",
    "    #exclude cases which violate business rules\n",
    "    comb_list = check_bus_rules_violations(comb_list)\n",
    "    \n",
    "    #set new_data equal to all the possible combinations\n",
    "    new_data = pd.concat(comb_list)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "557265d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Varlist\n",
    "#\n",
    "# @param df: dataframe to be copied for each combination of variable values in variable_list\n",
    "# @param variable_list: list of list of dictionaries specifying each variable and corresponding values\n",
    "# @param excluded_combinations: list of dictionaries specifying which combinations are not allowed\n",
    "# @param data_type: string specifying which data type this particular df is, e.g., 'real_comb' or 'synth_comb'\n",
    "#\n",
    "# @return df: concatenated copies of input df, one copy for every possible combination of variable values\n",
    "def combine_varlist(df, variable_list, excluded_combinations, data_type):\n",
    "    df = concat_combinations(df.copy(), variable_list, excluded_combinations)\n",
    "    df['data_type'] = data_type #specify data_type\n",
    "    print(data_type + ' shape: ' + str(df.shape))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb4a7e",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc6c9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "#\n",
    "# @param data_files: list of pandas dataframes, to be combined and saved\n",
    "# @param dest_filename: filename where data_files are to be saved\n",
    "def save_data(data_files, dest_filename):\n",
    "    data_exp = pd.concat(data_files) #concatenate data_files\n",
    "    print('Final data shape: ' + str(data_exp.shape)) #print out shape of concatenated dataframe\n",
    "    data_exp.to_csv(dest_filename, index = False) #save\n",
    "    print('Data has been saved to ' + dest_filename) #print save message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461e4b6",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca257e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../conf/archetypes/arch_combined_max.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_arch_combined_max.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoon_geslacht_vrouw': ['1']}], [{'relatie_partner_totaal_dagen_partner': ['720']}], [{'relatie_kind_huidige_aantal': ['2']}], [{'relatie_kind_heeft_kinderen': ['1']}], [{'relatie_kind_leeftijd_verschil_ouder_eerste_kind': ['20']}], [{'relatie_kind_basisschool_kind': ['2']}], [{'relatie_overig_historie_vorm__andere_inwonende': ['3']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['0']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0']}], [{'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km': ['1']}], [{'adres_recentste_wijk_delfshaven': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 1\n",
      "Length of comb_list after exclusion: 1\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (12645, 316)\n",
      "Final data shape: (12645, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_arch_combined_max.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_migrant_worker_language_reintegration.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_migrant_worker_language_reintegration.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'relatie_overig_historie_vorm__andere_inwonende': ['3']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['0', '1']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0', '720']}], [{'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km': ['1', '5']}], [{'adres_recentste_wijk_delfshaven': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}]]\n",
      "Excluded combinations:\n",
      "[{'persoonlijke_eigenschappen_taaleis_voldaan': '0', 'persoonlijke_eigenschappen_dagen_sinds_taaleis': '720'}, {'persoonlijke_eigenschappen_taaleis_voldaan': '1', 'persoonlijke_eigenschappen_dagen_sinds_taaleis': '0'}]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 8\n",
      "Length of comb_list after exclusion: 4\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (50580, 316)\n",
      "Final data shape: (50580, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_migrant_worker_language_reintegration.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_mother.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_arch_single_mother.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoon_geslacht_vrouw': ['ALL']}], [{'relatie_partner_totaal_dagen_partner': ['0', '720']}], [{'relatie_kind_huidige_aantal': ['0', '2']}], [{'relatie_kind_heeft_kinderen': ['ALL']}], [{'relatie_kind_leeftijd_verschil_ouder_eerste_kind': ['0', '20']}], [{'relatie_kind_basisschool_kind': ['0', '2']}], [{'belemmering_dagen_financiele_problemen': ['0', '700']}]]\n",
      "Excluded combinations:\n",
      "[{'relatie_kind_heeft_kinderen': '0', 'relatie_kind_huidige_aantal': '2'}, {'relatie_kind_heeft_kinderen': '0', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind': '20'}, {'relatie_kind_heeft_kinderen': '0', 'relatie_kind_basisschool_kind': '2'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_huidige_aantal': '0'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind': '0'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_basisschool_kind': '0'}, {'relatie_partner_huidige_partner___partner__gehuwd_': '0', 'relatie_partner_totaal_dagen_partner': '360'}, {'relatie_partner_huidige_partner___partner__gehuwd_': '0', 'relatie_partner_totaal_dagen_partner': '1000'}, {'relatie_partner_huidige_partner___partner__gehuwd_': '1', 'relatie_partner_totaal_dagen_partner': '0'}]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 128\n",
      "Length of comb_list after exclusion: 16\n",
      "Number of rows matching business rules:\n",
      " True     12508\n",
      "False      137\n",
      "dtype: int64\n",
      "synth_conditional shape: (200128, 316)\n",
      "Final data shape: (200128, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_arch_single_mother.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_mother_age.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_arch_single_mother_age.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoon_geslacht_vrouw': ['1']}], [{'relatie_partner_totaal_dagen_partner': ['720']}], [{'relatie_kind_huidige_aantal': ['2']}], [{'relatie_kind_heeft_kinderen': ['1']}], [{'relatie_kind_leeftijd_verschil_ouder_eerste_kind': ['20']}], [{'relatie_kind_basisschool_kind': ['2']}], [{'belemmering_dagen_financiele_problemen': ['700']}], [{'persoon_leeftijd_bij_onderzoek': ['28', '35', '45']}]]\n",
      "Excluded combinations:\n",
      "[{'relatie_kind_heeft_kinderen': '0', 'relatie_kind_huidige_aantal': '2'}, {'relatie_kind_heeft_kinderen': '0', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind': '20'}, {'relatie_kind_heeft_kinderen': '0', 'relatie_kind_basisschool_kind': '2'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_huidige_aantal': '0'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind': '0'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_basisschool_kind': '0'}, {'relatie_partner_huidige_partner___partner__gehuwd_': '0', 'relatie_partner_totaal_dagen_partner': '360'}, {'relatie_partner_huidige_partner___partner__gehuwd_': '0', 'relatie_partner_totaal_dagen_partner': '1000'}, {'relatie_partner_huidige_partner___partner__gehuwd_': '1', 'relatie_partner_totaal_dagen_partner': '0'}]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 3\n",
      "Length of comb_list after exclusion: 3\n",
      "Number of rows matching business rules:\n",
      " True     12508\n",
      "False      137\n",
      "dtype: int64\n",
      "synth_conditional shape: (37524, 316)\n",
      "Final data shape: (37524, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_arch_single_mother_age.csv\n",
      "\n",
      "Reading: ../conf/archetypes/parent.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_parent.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'relatie_kind_huidige_aantal': ['0', '2']}], [{'relatie_kind_heeft_kinderen': ['ALL']}], [{'relatie_kind_leeftijd_verschil_ouder_eerste_kind': ['0', '20']}], [{'relatie_kind_basisschool_kind': ['0', '2']}]]\n",
      "Excluded combinations:\n",
      "[{'relatie_kind_heeft_kinderen': '0', 'relatie_kind_huidige_aantal': '2'}, {'relatie_kind_heeft_kinderen': '0', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind': '20'}, {'relatie_kind_heeft_kinderen': '0', 'relatie_kind_basisschool_kind': '2'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_huidige_aantal': '0'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_leeftijd_verschil_ouder_eerste_kind': '0'}, {'relatie_kind_heeft_kinderen': '1', 'relatie_kind_basisschool_kind': '0'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (251, 316)\n",
      "Length comb_list before exclusion: 16\n",
      "Length of comb_list after exclusion: 2\n",
      "Number of rows matching business rules:\n",
      " True     12508\n",
      "False      137\n",
      "dtype: int64\n",
      "synth_conditional shape: (25016, 316)\n",
      "Final data shape: (25267, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_parent.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_migrant_worker_neighborhood.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_migrant_worker_neighborhood.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'relatie_overig_historie_vorm__andere_inwonende': ['0', '3']}], [{'adres_recentste_wijk_delfshaven': ['ALL']}, {'adres_recentste_wijk_stadscentru': ['ALL']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (1187, 316)\n",
      "Length comb_list before exclusion: 4\n",
      "Length of comb_list after exclusion: 4\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (50580, 316)\n",
      "Final data shape: (51767, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_migrant_worker_neighborhood.csv\n",
      "\n",
      "Reading: ../conf/archetypes/good_dutch.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_good_dutch.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoonlijke_eigenschappen_spreektaal': ['57', '4']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['1']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['720']}], [{'afspraak_afgelopen_jaar_ontheffing_taaleis': ['1']}], [{'contacten_onderwerp_beoordelen_taaleis': ['1']}], [{'afspraak_verzenden_beschikking_i_v_m__niet_voldoen_aan_wet_taaleis': ['0']}], [{'persoonlijke_eigenschappen_taaleis_schrijfv_ok': ['1']}], [{'persoonlijke_eigenschappen_spreektaal_anders': ['0']}], [{'contacten_onderwerp_boolean_beoordelen_taaleis': ['1']}], [{'contacten_onderwerp_boolean_taaleis___voldoet': ['1']}], [{'belemmering_hist_taal': ['0']}], [{'persoonlijke_eigenschappen_nl_spreken1': ['0']}], [{'persoonlijke_eigenschappen_nl_spreken2': ['0']}], [{'persoonlijke_eigenschappen_nl_spreken3': ['1']}], [{'persoonlijke_eigenschappen_nl_begrijpen3': ['1']}], [{'persoonlijke_eigenschappen_nl_schrijven0': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven1': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven2': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven3': ['1']}], [{'persoonlijke_eigenschappen_nl_schrijvenfalse': ['0']}], [{'persoonlijke_eigenschappen_nl_lezen3': ['0']}], [{'persoonlijke_eigenschappen_nl_lezen4': ['1']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 2\n",
      "Length of comb_list after exclusion: 2\n",
      "Number of rows matching business rules:\n",
      " True     12508\n",
      "False      137\n",
      "dtype: int64\n",
      "synth_conditional shape: (25016, 316)\n",
      "Final data shape: (25016, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_good_dutch.csv\n",
      "\n",
      "Reading: ../conf/archetypes/language_requirement.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_language_requirement.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoonlijke_eigenschappen_taaleis_voldaan': ['ALL']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0', '720']}]]\n",
      "Excluded combinations:\n",
      "[{'persoonlijke_eigenschappen_taaleis_voldaan': '0', 'persoonlijke_eigenschappen_dagen_sinds_taaleis': '720'}, {'persoonlijke_eigenschappen_taaleis_voldaan': '1', 'persoonlijke_eigenschappen_dagen_sinds_taaleis': '0'}]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (11, 316)\n",
      "Length comb_list before exclusion: 6\n",
      "Length of comb_list after exclusion: 4\n",
      "Number of rows matching business rules:\n",
      " True     12508\n",
      "False      137\n",
      "dtype: int64\n",
      "synth_conditional shape: (50032, 316)\n",
      "Final data shape: (50043, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_language_requirement.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_combined_min.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_arch_combined_min.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoon_geslacht_vrouw': ['0']}], [{'relatie_partner_totaal_dagen_partner': ['0']}], [{'relatie_kind_huidige_aantal': ['0']}], [{'relatie_kind_heeft_kinderen': ['0']}], [{'relatie_kind_leeftijd_verschil_ouder_eerste_kind': ['0']}], [{'relatie_kind_basisschool_kind': ['0']}], [{'relatie_overig_historie_vorm__andere_inwonende': ['0']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['1']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['720']}], [{'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km': ['5']}], [{'adres_recentste_wijk_delfshaven': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 1\n",
      "Length of comb_list after exclusion: 1\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (12645, 316)\n",
      "Final data shape: (12645, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_arch_combined_min.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_migrant_worker_language.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_migrant_worker_language.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'relatie_overig_historie_vorm__andere_inwonende': ['3']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['0', '1']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0', '720']}], [{'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km': ['1', '5']}], [{'adres_recentste_wijk_delfshaven': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}]]\n",
      "Excluded combinations:\n",
      "[{'persoonlijke_eigenschappen_taaleis_voldaan': '0', 'persoonlijke_eigenschappen_dagen_sinds_taaleis': '720'}, {'persoonlijke_eigenschappen_taaleis_voldaan': '1', 'persoonlijke_eigenschappen_dagen_sinds_taaleis': '0'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 8\n",
      "Length of comb_list after exclusion: 4\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (50580, 316)\n",
      "Final data shape: (50580, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_migrant_worker_language.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_migrant_worker_comment_no_comment.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_migrant_worker_comment_no_comment.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'relatie_overig_historie_vorm__andere_inwonende': ['3']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['0']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0']}], [{'contacten_onderwerp_boolean_beoordelen_taaleis': ['0']}], [{'afspraak_verzenden_beschikking_i_v_m__niet_voldoen_aan_wet_taaleis': ['0']}], [{'contacten_onderwerp_boolean_taaleis___voldoet': ['0']}], [{'afspraak_afgelopen_jaar_ontheffing_taaleis': ['0']}], [{'contacten_onderwerp_beoordelen_taaleis': ['0']}], [{'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km': ['1']}], [{'adres_recentste_wijk_delfshaven': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}], [{'competentie_plannen_en_organiseren': ['1', '0']}], [{'persoonlijke_eigenschappen_opstelling': ['1', '0']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 4\n",
      "Length of comb_list after exclusion: 4\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (50580, 316)\n",
      "Final data shape: (50580, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_migrant_worker_comment_no_comment.csv\n",
      "\n",
      "Reading: ../conf/archetypes/arch_migrant_worker_language_all.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_migrant_worker_language_all.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'relatie_overig_historie_vorm__andere_inwonende': ['3']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['0']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0']}], [{'contacten_onderwerp_boolean_beoordelen_taaleis': ['0']}], [{'afspraak_verzenden_beschikking_i_v_m__niet_voldoen_aan_wet_taaleis': ['0']}], [{'contacten_onderwerp_boolean_taaleis___voldoet': ['0']}], [{'afspraak_afgelopen_jaar_ontheffing_taaleis': ['0']}], [{'contacten_onderwerp_beoordelen_taaleis': ['0']}], [{'persoonlijke_eigenschappen_uitstroom_verw_vlgs_km': ['1']}], [{'adres_recentste_wijk_delfshaven': ['1']}], [{'adres_recentste_wijk_stadscentru': ['0']}], [{'adres_recentste_wijk_charlois': ['0']}], [{'adres_recentste_wijk_feijenoord': ['0']}], [{'adres_recentste_wijk_ijsselmonde': ['0']}], [{'adres_recentste_wijk_kralingen_c': ['0']}], [{'adres_recentste_wijk_noord': ['0']}], [{'adres_recentste_wijk_other': ['0']}], [{'adres_recentste_wijk_prins_alexa': ['0']}], [{'adres_recentste_buurt_nieuwe_westen': ['0']}], [{'adres_recentste_buurt_other': ['1']}], [{'adres_recentste_buurt_groot_ijsselmonde': ['0']}], [{'adres_recentste_buurt_oude_noorden': ['0']}], [{'adres_recentste_buurt_vreewijk': ['0']}], [{'adres_recentst_onderdeel_rdam': ['1']}], [{'adres_recentste_plaats_rotterdam': ['1']}], [{'adres_recentste_plaats_other': ['0']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 1\n",
      "Length of comb_list after exclusion: 1\n",
      "Number of rows matching business rules:\n",
      " True    12645\n",
      "dtype: int64\n",
      "synth_conditional shape: (12645, 316)\n",
      "Final data shape: (12645, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_migrant_worker_language_all.csv\n",
      "\n",
      "Reading: ../conf/archetypes/bad_dutch.ini\n",
      "Destination Filename: ../data/03_experiment_input/20221119_jb_struggling_dutch.csv\n",
      "Real Source FP: ../data/00_hidden/td_numeric.csv\n",
      "Synth Source FP: ../data/01_raw/synth_data.csv\n",
      "Variable list:\n",
      "[[{'persoonlijke_eigenschappen_spreektaal': ['0', '4']}], [{'persoonlijke_eigenschappen_taaleis_voldaan': ['0']}], [{'persoonlijke_eigenschappen_dagen_sinds_taaleis': ['0']}], [{'afspraak_afgelopen_jaar_ontheffing_taaleis': ['0']}], [{'contacten_onderwerp_beoordelen_taaleis': ['0']}], [{'afspraak_verzenden_beschikking_i_v_m__niet_voldoen_aan_wet_taaleis': ['1']}], [{'persoonlijke_eigenschappen_taaleis_schrijfv_ok': ['0']}], [{'persoonlijke_eigenschappen_spreektaal_anders': ['1']}], [{'contacten_onderwerp_boolean_beoordelen_taaleis': ['0']}], [{'contacten_onderwerp_boolean_taaleis___voldoet': ['0']}], [{'belemmering_hist_taal': ['1']}], [{'persoonlijke_eigenschappen_nl_spreken1': ['1']}], [{'persoonlijke_eigenschappen_nl_spreken2': ['0']}], [{'persoonlijke_eigenschappen_nl_spreken3': ['0']}], [{'persoonlijke_eigenschappen_nl_begrijpen3': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven0': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven1': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven2': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijven3': ['0']}], [{'persoonlijke_eigenschappen_nl_schrijvenfalse': ['0']}], [{'persoonlijke_eigenschappen_nl_lezen3': ['0']}], [{'persoonlijke_eigenschappen_nl_lezen4': ['0']}]]\n",
      "Excluded combinations:\n",
      "[]\n",
      "All chosen variables correspondond to columns in the dataset\n",
      "synth copied, shape: (0, 316)\n",
      "Length comb_list before exclusion: 2\n",
      "Length of comb_list after exclusion: 2\n",
      "Number of rows matching business rules:\n",
      " True     12508\n",
      "False      137\n",
      "dtype: int64\n",
      "synth_conditional shape: (25016, 316)\n",
      "Final data shape: (25016, 316)\n",
      "Data has been saved to ../data/03_experiment_input/20221119_jb_struggling_dutch.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CHECK: set flag depending on whether you have access to the real training data\n",
    "training_access = False\n",
    "\n",
    "# Data Generator\n",
    "#\n",
    "# Purpose: wrapper function; once all the other functions have been loaded, you only need to run this function to \n",
    "# generate data for each config file in '../conf'\n",
    "def data_generator():\n",
    "    directory_in_str = '../conf/archetypes' #CHECK: file path of ini files\n",
    "    directory = os.fsencode(directory_in_str)\n",
    "    \n",
    "    \n",
    "    #iterate over all ini config files\n",
    "    for file in os.listdir(directory):\n",
    "        filename = directory_in_str + \"/\" + os.fsdecode(file)\n",
    "        \n",
    "        #only load ini files\n",
    "        if not filename.endswith('.ini'):\n",
    "            continue\n",
    "        print('Reading: ' + filename)\n",
    "        \n",
    "        #read ini file\n",
    "        conf = read_config(filename)\n",
    "        \n",
    "        #load synthetic and real data\n",
    "        if training_access:\n",
    "            real = load_data(conf['real_fp'])\n",
    "        synth = load_data(conf['synth_fp'])\n",
    "        \n",
    "        #check user inputs\n",
    "        check_user_inputs(synth, conf['variable_list'])\n",
    "        \n",
    "        #generate copy of real data for simple statistical parity test\n",
    "        if training_access:\n",
    "            real_exp = slice_data(real, conf['variable_list'], 'real') \n",
    "        synth_exp = slice_data(synth, conf['variable_list'], 'synth')\n",
    "        \n",
    "        #generate data for conditional statistical parity test\n",
    "        if training_access:\n",
    "            real_comb = combine_varlist(real, conf['variable_list'], conf['excluded_combinations'], 'real_conditional')\n",
    "            if real_comb.empty:\n",
    "                raise Exception('Real Combinations Dataframe is empty! You might want to specify excluded combinations in the config file...')\n",
    "        synth_comb = combine_varlist(synth, conf['variable_list'], conf['excluded_combinations'], 'synth_conditional')\n",
    "        if synth_comb.empty:\n",
    "            raise Exception('Synth Combinations Dataframe is empty! You might want to specify excluded combinations in the config file...')\n",
    "        \n",
    "        if training_access:\n",
    "            save_data([real_exp, real_comb, synth_exp, synth_comb], conf['dest_filename'])\n",
    "        else:\n",
    "            save_data([synth_exp, synth_comb], conf['dest_filename'])\n",
    "        print()\n",
    "\n",
    "data_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
